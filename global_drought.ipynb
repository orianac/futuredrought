{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.32.2.61:35837</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/0000-0003-1376-3835/proxy/8787/status' target='_blank'>/user/0000-0003-1376-3835/proxy/8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>5</li>\n",
       "  <li><b>Cores: </b>10</li>\n",
       "  <li><b>Memory: </b>57.50 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.32.2.61:35837' processes=5 threads=10, memory=57.50 GB>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://10.32.2.61:35837\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  if __name__ == '__main__':\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/intake/source/discovery.py:136: FutureWarning: The drivers ['geojson', 'postgis', 'shapefile', 'spatialite'] do not specify entry_points and were only discovered via a package scan. This may break in a future release of intake. The packages should be updated.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n",
    "import intake\n",
    "import gcsfs\n",
    "import fsspec\n",
    "import xesmf as xe\n",
    "import warnings\n",
    "import fiona\n",
    "import rasterio\n",
    "import regionmask\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "# util.py is in the local directory\n",
    "# it contains code that is common across project notebooks\n",
    "# or routines that are too extensive and might otherwise clutter\n",
    "# the notebook design\n",
    "col_url = 'https://raw.githubusercontent.com/orianac/futuredrought/develop/pangeo-zarr-cmip6.json'\n",
    "# col_url = \"https://raw.githubusercontent.com/NCAR/intake-esm-datastore/master/catalogs/pangeo-cmip6.json\"\n",
    "col = intake.open_esm_datastore(col_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 250) # so that we can see all of the different experiments available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Different variable options : \n",
    "#'mrro' - runoff\n",
    "#'snw' - SWE\n",
    " #hfls - latent heat\n",
    " # mrros - surface runoff\n",
    " # mrso - soil moisture\n",
    " # pr - precipitation\n",
    " # tas - mean daily air temperature\n",
    " # prra - rainfall rate\n",
    " # prsn - snowfall rate\n",
    "\n",
    "variable_of_interest = 'mrro'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load your dataset at the timestep you want (monthly or daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analysis_timestep = 'Lmon' # or 'day'\n",
    "cat = col.search(experiment_id=['historical', \n",
    "                                'ssp585', \n",
    "                               'ssp370',\n",
    "                                'ssp126', \n",
    "                                'ssp245',],#, 'ssp126', 'ssp245', 'ssp370'],\n",
    "                 table_id=analysis_timestep,             \n",
    "                 variable_id=variable_of_interest) \n",
    "# this is a hack just to get around the different grid_label strings\n",
    "cat.df['grid_label']='gn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_slice = slice('2070','2099')\n",
    "historical_slice = slice('1985','2014')\n",
    "slices = {'historical': slice('1985','2014'),\n",
    "          'ssp585': slice('2070','2099')}\n",
    "slices_ranges = {'historical': pd.date_range('1985-01-01', '2014-12-31', freq='M'),\n",
    "                 'ssp585': pd.date_range('2070-01-01', '2099-12-31', freq='M')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |███████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n",
      "             \n",
      "--> There are 150 group(s)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6225ed93cfe48f8a12bc2537ca03b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=150.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScenarioMIP.CCCma.CanESM5.ssp370.Lmon.gn\n",
      "ScenarioMIP.CCCma.CanESM5.ssp585.Lmon.gn\n",
      "ScenarioMIP.CCCma.CanESM5.ssp126.Lmon.gn\n",
      "CMIP.CCCma.CanESM5.historical.Lmon.gn\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dset_dict = cat.to_dataset_dict(zarr_kwargs={'consolidated': True, 'decode_times': False})\n",
    "\n",
    "ds_dict = {}\n",
    "for name, ds in tqdm(dset_dict.items()):\n",
    "    try:\n",
    "# rename spatial dimensions if necessary\n",
    "        if ('longitude' in ds.dims) and ('latitude' in ds.dims):\n",
    "            ds = ds.rename({'longitude':'lon', 'latitude': 'lat'}) # some models labelled dimensions differently...\n",
    "        ds = xr.decode_cf(ds) # temporary hack, not sure why I need this but has to do with calendar-aware metadata on the time variable\n",
    "    #     ds = ds.sel(time=time_slice) # subset the data for the time period of interest\n",
    "\n",
    "        # drop redundant variables (like \"height: 2m\")\n",
    "        for coord in ds.coords:\n",
    "            if coord not in ['lat','lon','time']:\n",
    "                ds = ds.drop(coord)\n",
    "\n",
    "        # Add dataset to dictionary, selecting first member_id for each simulation since we'll just use\n",
    "        # one ensemble member right now\n",
    "        ds_dict[name] = ds.isel(member_id=0)\n",
    "    except:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_change(historic, future, percentage=True):\n",
    "    if percentage:\n",
    "        return (future - historic)/(historic) * 100\n",
    "    else:\n",
    "        return future - historic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annual_mean(ts):\n",
    "    return ts.mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdev(ts, timestep, freq='monthly'):\n",
    "    if timestep == 'Lmon':\n",
    "        return ts.std(dim='time')\n",
    "    elif timestep == 'day':\n",
    "        if freq == 'monthly':\n",
    "            return ts.resample(time='M').mean().std(dim='time')\n",
    "        else:\n",
    "            print('calculating daily')\n",
    "            return ts.std(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_runoff(ts):\n",
    "    return ts.resample(time='M').mean().groupby('time.year').min().min(dim='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cartopy_elements(ax):\n",
    "    ax.set_global()\n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cartopy.feature.LAND, color='black')\n",
    "    ax.add_feature(cartopy.feature.OCEAN, color='grey')\n",
    "    ax.add_feature(cartopy.feature.COASTLINE)\n",
    "    ax.add_feature(cartopy.feature.BORDERS, linestyle='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nicely(ax, ds, vmin, vmax, cmap='viridis', cbar_label=None, title=None):\n",
    "\n",
    "    # plot.contourf(ax=ax, levels=n.arange(min_var, max_var, interval))\n",
    "    ds.plot(ax=ax, transform=ccrs.PlateCarree(),\n",
    "            vmin=vmin, vmax=vmax, cmap=cmap, \n",
    "            levels=11,\n",
    "           cbar_kwargs={'label': cbar_label})\n",
    "    ax.set_title(title)\n",
    "    add_cartopy_elements(ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load and regrid to a common grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_qflow(da, rolling_period=30, minimum=True):\n",
    "    '''calculate n-day (based upon rolling_period) moving average.\n",
    "    if minimum, returns the minimum value in the 30 year period\n",
    "    if not, returns the average'''\n",
    "    if minimum:\n",
    "        return da.rolling(time=rolling_period, \n",
    "                          center=True).mean().groupby('time.year').min().min(dim='year')\n",
    "    else:\n",
    "        return da.rolling(time=rolling_period, \n",
    "                          center=True).mean().groupby('time.year').min().mean(dim='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variability(da):\n",
    "    return da.resample(time='M').mean().std(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(sim, obs, method):\n",
    "    if method=='percent':\n",
    "        return (sim-obs)/obs*100\n",
    "    elif method=='absolute':\n",
    "        return sim - obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the countries shapefile and make masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_intraannual_range(da, timestep):\n",
    "    ''' \n",
    "    calculate yearly range based upon monthly runoff\n",
    "    '''\n",
    "    if timestep == 'Lmon':\n",
    "        return da.groupby('time.year').max(dim='time') - \\\n",
    "            da.groupby('time.year').min(dim='time')\n",
    "    elif timestep == 'day':\n",
    "        return da.resample(time='M').mean().groupby('time.year').max(dim='time') - \\\n",
    "            da.resample(time='M').mean().groupby('time.year').min(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowest_10thpercentile(da, timestep):\n",
    "    if timestep == 'Lmon':\n",
    "        return da.groupby('time.year').min(dim='time').compute().quantile(0.1, dim='year')\n",
    "    elif timestep == 'day':\n",
    "        return da.resample(time='M').mean().groupby('time.year').min(dim='time').compute().quantile(0.1, dim='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basin_average_intraannual_range(monthly_ds, \n",
    "                                   multiple_ensemble_members=False,\n",
    "                                  return_ensemble=False):\n",
    "    basin_mean = monthly_ds.mean(dim= ['latitude', 'longitude'])\n",
    "    hydrologic_range = monthly_intraannual_range(basin_mean, 'Lmon').mean(dim='year')\n",
    "                    # present the range normalized by total runoff\n",
    "    basin_mean_range = hydrologic_range*30/(basin_mean.mean(dim='time')*365)\n",
    "    if multiple_ensemble_members:\n",
    "        if return_ensemble:\n",
    "            return basin_mean_range\n",
    "        else:\n",
    "            return float(basin_mean_range.mean(dim='gcm'))\n",
    "    else:\n",
    "        return float(basin_mean_range.values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_gridded_to_basins(da, masks, geographic_gdf_in, \n",
    "                          comparison_da=None, masks2=None, num_cells_threshold=1):\n",
    "    '''Input: gridded xarray data array on lat/lon coordinates\n",
    "    we assume that the da is the obs dataset and comparison_da is the sim,\n",
    "    so any comparisons are w.r.t. the da'''\n",
    "    da = da.rename({'lon': 'longitude',\n",
    "                       'lat': 'latitude'})\n",
    "    da = da.assign_coords(longitude=(((da.longitude + 180) % 360) \n",
    "                                         - 180)).sortby('longitude')\n",
    "    geographic_gdf = geographic_gdf_in.copy(deep=True)\n",
    "    geographic_gdf['mean'] = np.nan\n",
    "    geographic_gdf['h_range'] = np.nan\n",
    "    geographic_gdf['NumCells'] = np.nan\n",
    "    lat = masks.latitude.values\n",
    "    lon = masks.longitude.values\n",
    "    if comparison_da is not None:\n",
    "        comparison_da = comparison_da.rename({'lon': 'longitude',\n",
    "                       'lat': 'latitude'})\n",
    "        comparison_da = comparison_da.assign_coords(longitude=(((comparison_da.longitude + 180) % 360) \n",
    "                                         - 180)).sortby('longitude')\n",
    "    for ID_REGION in tqdm(geographic_gdf.index.values):\n",
    "        sel_mask = masks.where(masks == ID_REGION).values\n",
    "        num_cells = (~np.isnan(sel_mask)).sum()\n",
    "        geographic_gdf.at[ID_REGION, 'NumCells'] = num_cells\n",
    "        \n",
    "        if num_cells < num_cells_threshold:\n",
    "#             print('{} has zero cells!'.format(ID_REGION))\n",
    "            continue\n",
    "        id_lon = lon[np.where(~np.all(np.isnan(sel_mask), axis=0))]\n",
    "        id_lat = lat[np.where(~np.all(np.isnan(sel_mask), axis=1))]\n",
    "        trimmed_mask = masks.sel(latitude = slice(id_lat[0], id_lat[-1]), \n",
    "                        longitude = slice(id_lon[0], id_lon[-1]))\n",
    "\n",
    "        out_sel = da.sel(latitude = slice(id_lat[0], id_lat[-1]), \n",
    "                        longitude = slice(id_lon[0], id_lon[-1])\n",
    "                       ).compute()\n",
    "        out_sel = out_sel.where(trimmed_mask == ID_REGION)\n",
    "        if comparison_da is None:\n",
    "            mean_to_fill = float(out_sel.mean().values)\n",
    "            hr_to_fill = basin_average_intraannual_range(out_sel)\n",
    "        else:\n",
    "            comparison_da_sel = comparison_da.sel(latitude = slice(id_lat[0], id_lat[-1]), \n",
    "                        longitude = slice(id_lon[0], id_lon[-1])\n",
    "                       ).compute().where(masks == ID_REGION)\n",
    "            # comparison_da is the simulated \n",
    "            if metric=='mean':\n",
    "                value_to_fill = (comparison_da_sel - out_sel).mean(\n",
    "                                    dim=['latitude', 'longitude'])/out_sel.mean(dim=['latitude', 'longitude'])*100\n",
    "            elif metric=='std':\n",
    "                value_to_fill = (comparison_da_sel - out_sel).mean(\n",
    "                                    dim=['latitude', 'longitude'])/out_sel.mean(dim=['latitude', 'longitude'])*100\n",
    "            elif metric=='hydrologic_range':\n",
    "                base_case = basin_average_intraannual_range(out_sel).mrro.values\n",
    "                comparison_case = basin_average_intraannual_range(comparison_da_sel,\n",
    "                                                                 multiple_ensemble_members=True).mrro.values\n",
    "                value_to_fill = comparison_case - base_case\n",
    "        geographic_gdf.at[ID_REGION, 'mean'] = mean_to_fill\n",
    "        geographic_gdf.at[ID_REGION, 'h_range'] = hr_to_fill\n",
    "    return geographic_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the basin and country shapefile and make masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterize_shapefile(shapefile, sample_grid_file, name):\n",
    "    '''\n",
    "    Inputs:\n",
    "    shapefile: shapefile of the regions you want to rasterize\n",
    "    sample_grid_file: xarray datarray with the grid you want to rasterize the shapefile to\n",
    "    name: the name of the column in the shapefile that has the labels for the polygons\n",
    "    '''\n",
    "    sample_grid_file = sample_grid_file.rename({'lon': 'longitude',\n",
    "                   'lat': 'latitude'})\n",
    "    sample_grid_file = sample_grid_file.assign_coords(longitude=(((sample_grid_file.longitude + 180) % 360) \n",
    "                                     - 180)).sortby('longitude')\n",
    "    mask_poly = regionmask.Regions_cls(name='mask', \n",
    "                                        numbers=list(range(0,len(shapefile)-1)), \n",
    "                                        names=list(shapefile[name]), \n",
    "                                        abbrevs=list(shapefile[name]), \n",
    "                                        outlines=list(shapefile.geometry.values[i] \n",
    "                                                      for i in range(0,len(shapefile)-1)))\n",
    "    mask = mask_poly.mask(sample_grid_file, lat_name='latitude', \n",
    "                            lon_name='longitude',\n",
    "                            wrap_lon=False)\n",
    "    return mask, mask_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine basin shapefile and country shapefile to find every overlap and we'll call that SUBBASIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreate_shapefile = False\n",
    "if recreate_shapefile:\n",
    "    basins = gpd.read_file('shapefile_test/Major_Basins_of_the_World.dbf')\n",
    "    # Remove the basins that don't have geometries attached to them\n",
    "    basins = basins[basins.geometry!=None]\n",
    "\n",
    "    countries = gpd.read_file('Countries_WGS84.dbf')\n",
    "    subbasins = gpd.overlay(basins, countries, how='union')\n",
    "    # make a new column which has a combined ID\n",
    "    subbasins['SUBBASIN_N'] = subbasins['NAME']+'_'+subbasins['CNTRY_NAME']\n",
    "    subbasins = subbasins[~subbasins['SUBBASIN_N'].isna()]\n",
    "    subbasins.to_file('country_basin_join.shp')\n",
    "else:\n",
    "    basins = gpd.read_file('shapefile_test/Major_Basins_of_the_World.dbf')\n",
    "    basins = basins[basins.geometry!=None]\n",
    "    subbasins = gpd.read_file('country_basin_join.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate grid means for each different GCM simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick out the GCMs that have a corresponding historical setup\n",
    "setup_list = list(dset_dict.keys())\n",
    "valid_setups = {}\n",
    "for setup in ['ssp585', 'ssp370', 'ssp126', 'ssp245']:\n",
    "    valid_setups[setup] = []\n",
    "    for gcm_run in setup_list:\n",
    "        if setup in gcm_run:\n",
    "            gcm_label = '.'.join(gcm_run.split('.')[1:3])\n",
    "            if 'CMIP.{}.historical.Lmon.gn'.format(gcm_label) in setup_list:\n",
    "                valid_setups[setup].append(gcm_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOAA-GFDL.GFDL-CM4 not present in setup ssp370\n",
      "NOAA-GFDL.GFDL-CM4 not present in setup ssp126\n",
      "FIO-QLNM.FIO-ESM-2-0 not present in setup ssp370\n"
     ]
    }
   ],
   "source": [
    "for gcm in valid_setups['ssp585']:\n",
    "    for setup in ['ssp585', 'ssp370', 'ssp126', 'ssp245']:\n",
    "        if gcm in valid_setups[setup]:\n",
    "            continue\n",
    "        else:\n",
    "            print('{} not present in setup {}'.format(gcm, setup))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate all of the basin changes separated out by changes per country in the basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "subbasins_changes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC.BCC-CSM2-MR\n",
      "Woohoo! You've finished rasterizing your shapefile for BCC.BCC-CSM2-MR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616cc48bea6844c9851aa6b2747ebf26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=620.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Excellent! You've finished the historical shapefile for BCC.BCC-CSM2-MR\n",
      "ssp585 CCCma.CanESM5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd40be637e1c4f3fa67d6c19d8280627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=620.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CAMS.CAMS-CSM1-0\n",
      "CAMS.CAMS-CSM1-0 already done!\n",
      "CSIRO-ARCCSS.ACCESS-CM2\n",
      "CSIRO-ARCCSS.ACCESS-CM2 already done!\n",
      "EC-Earth-Consortium.EC-Earth3-Veg\n",
      "EC-Earth-Consortium.EC-Earth3-Veg already done!\n",
      "MIROC.MIROC-ES2L\n",
      "MIROC.MIROC-ES2L already done!\n",
      "INM.INM-CM4-8\n",
      "INM.INM-CM4-8 already done!\n",
      "INM.INM-CM5-0\n",
      "INM.INM-CM5-0 already done!\n",
      "MRI.MRI-ESM2-0\n",
      "MRI.MRI-ESM2-0 already done!\n",
      "NIMS-KMA.KACE-1-0-G\n",
      "NIMS-KMA.KACE-1-0-G already done!\n",
      "NOAA-GFDL.GFDL-CM4\n",
      "NOAA-GFDL.GFDL-CM4 already done!\n",
      "UA.MCM-UA-1-0\n",
      "UA.MCM-UA-1-0 already done!\n",
      "NCAR.CESM2\n",
      "NCAR.CESM2 already done!\n",
      "CSIRO.ACCESS-ESM1-5\n",
      "CSIRO.ACCESS-ESM1-5 already done!\n",
      "CCCma.CanESM5-CanOE\n",
      "CCCma.CanESM5-CanOE already done!\n",
      "MIROC.MIROC6\n",
      "MIROC.MIROC6 already done!\n",
      "FIO-QLNM.FIO-ESM-2-0\n",
      "FIO-QLNM.FIO-ESM-2-0 already done!\n",
      "MPI-M.MPI-ESM1-2-LR\n",
      "MPI-M.MPI-ESM1-2-LR already done!\n",
      "CNRM-CERFACS.CNRM-ESM2-1\n",
      "Woohoo! You've finished rasterizing your shapefile for CNRM-CERFACS.CNRM-ESM2-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a273cac9600146f892197811a8662cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=620.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Excellent! You've finished the historical shapefile for CNRM-CERFACS.CNRM-ESM2-1\n",
      "ssp585 CCCma.CanESM5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96d92f017e24b50875b961671278190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=620.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MOHC.UKESM1-0-LL\n",
      "Woohoo! You've finished rasterizing your shapefile for MOHC.UKESM1-0-LL\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c04253a68f84e03990c4aee6b951d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=620.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Excellent! You've finished the historical shapefile for MOHC.UKESM1-0-LL\n",
      "ssp585 CCCma.CanESM5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c821421df0240d8895966700554a3d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=620.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NCAR.CESM2-WACCM\n",
      "Woohoo! You've finished rasterizing your shapefile for NCAR.CESM2-WACCM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f1d1eed64849b283bffa6a142cf511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=620.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Excellent! You've finished the historical shapefile for NCAR.CESM2-WACCM\n",
      "ssp585 CCCma.CanESM5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae114011848446cbd0b40fa9461018e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=620.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNRM-CERFACS.CNRM-CM6-1\n",
      "Woohoo! You've finished rasterizing your shapefile for CNRM-CERFACS.CNRM-CM6-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89df3bd6ace54648b619a005e77ebfe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=620.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Excellent! You've finished the historical shapefile for CNRM-CERFACS.CNRM-CM6-1\n",
      "ssp585 CCCma.CanESM5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d871835df03a4cc5b6289d72d94dace1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=620.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPSL.IPSL-CM6A-LR\n",
      "Woohoo! You've finished rasterizing your shapefile for IPSL.IPSL-CM6A-LR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0e0b1fe0b6405f91253e76096da500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=620.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Excellent! You've finished the historical shapefile for IPSL.IPSL-CM6A-LR\n",
      "ssp585 CCCma.CanESM5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ee98597034434c94522eb6ffba1a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=620.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CCCma.CanESM5\n",
      "CCCma.CanESM5 already done!\n"
     ]
    }
   ],
   "source": [
    "# calculate basin averages for each of the 20 GCMs\n",
    "recalculate_basin_means=True\n",
    "recalculate_historical=True\n",
    "recalculate_future=True\n",
    "if recalculate_basin_means:\n",
    "    for gcm_label in valid_setups['ssp585']: \n",
    "        print(gcm_label)\n",
    "        if gcm_label in ['CSIRO-ARCCSS.ACCESS-CM2',\n",
    "             'MIROC.MIROC-ES2L',\n",
    "             'CCCma.CanESM5-CanOE',\n",
    "             'INM.INM-CM5-0',\n",
    "              'CAMS.CAMS-CSM1-0',\n",
    "              'EC-Earth-Consortium.EC-Earth3-Veg',\n",
    "              'INM.INM-CM4-8',\n",
    "              'CSIRO-ARCCSS.ACCESS-CM2',\n",
    "              'CCCma.CanESM5',\n",
    "             'UA.MCM-UA-1-0',\n",
    "             'NIMS-KMA.KACE-1-0-G',\n",
    "             'NOAA-GFDL.GFDL-CM4',\n",
    "             'CSIRO.ACCESS-ESM1-5',\n",
    "             'NCAR.CESM2',\n",
    "             'MRI.MRI-ESM2-0',\n",
    "         'FIO-QLNM.FIO-ESM-2-0',\n",
    "         'MIROC.MIROC6',\n",
    "         'MPI-M.MPI-ESM1-2-LR']:\n",
    "            print('{} already done!'.format(gcm_label))\n",
    "            continue\n",
    "        \n",
    "        historical_setup = 'CMIP.{}.historical.Lmon.gn'.format(gcm_label)\n",
    "\n",
    "        \n",
    "        # first make the raster-to-polygon mapping for this grid\n",
    "        sample_file = ds_dict[historical_setup].isel(time=0).compute()\n",
    "        raster_subbasins, subbasin_poly_mask = rasterize_shapefile(subbasins, \n",
    "                                                                   sample_file, \n",
    "                                                                   'SUBBASIN_N')\n",
    "\n",
    "        print(\"Woohoo! You've finished rasterizing your shapefile for {}\".format(gcm_label))\n",
    "        if recalculate_historical:\n",
    "            subbasins_historical = map_gridded_to_basins(ds_dict[historical_setup].mrro, \n",
    "                                               raster_subbasins, subbasins)\n",
    "            subbasins_historical.to_file('{}_polygon_historical.shp'.format(gcm_label))\n",
    "            print(\"Excellent! You've finished the historical shapefile for {}\".format(gcm_label))\n",
    "\n",
    "        # rasterize the subbasin differently for every \n",
    "        if recalculate_future:\n",
    "            subbasins_future, subbasins_changes = {}, {}\n",
    "            for setup in ['ssp585']: # eventually do it for all setups\n",
    "                print(setup, gcm)\n",
    "                future_setup = 'ScenarioMIP.{}.{}.Lmon.gn'.format(gcm_label, setup)\n",
    "                subbasins_future[setup] = map_gridded_to_basins(ds_dict[future_setup].mrro, \n",
    "                                               raster_subbasins, subbasins)\n",
    "\n",
    "\n",
    "                subbasins_future[setup].to_file('{}_{}_polygon_future.shp'.format(gcm_label, setup))\n",
    "\n",
    "                subbasins_changes[setup] = subbasins.copy(deep=True)\n",
    "                for metric in ['mean', 'h_range']:\n",
    "                    subbasins_changes[setup][metric] = (subbasins_future[setup][metric] - \n",
    "                                                        subbasins_historical[metric])/subbasins_historical[metric]\n",
    "                subbasins_changes[setup].to_file('{}_{}_polygon_changes.shp'.format(gcm_label, setup))\n",
    "else:\n",
    "    subbasins_with_mean_changes = gpd.read_file('MIROC6_polygon_changes.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate averages for each individual basin (full, not separated into country parts)\n",
    "## only do it for international basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "basins = basins[basins['Q3']=='International catchments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n",
      "Awesome news: {} was already completed!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'CMIP.CCCma.CanESM5.historical.Lmon.gn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-7e90e1426f8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# first make the raster-to-polygon mapping for this grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0msample_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistorical_setup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         raster_basins, basin_poly_mask = rasterize_shapefile(basins, \n\u001b[1;32m     36\u001b[0m                                                                    \u001b[0msample_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CMIP.CCCma.CanESM5.historical.Lmon.gn'"
     ]
    }
   ],
   "source": [
    "# calculate basin averages for each of the 20 GCMs\n",
    "recalculate_basin_means=True\n",
    "recalculate_historical=True\n",
    "recalculate_future=True\n",
    "if recalculate_basin_means:\n",
    "    for gcm_label in valid_setups['ssp585']:\n",
    "        if gcm_label in ['CAMS.CAMS-CSM1-0',\n",
    "                        'BCC.BCC-CSM2-MR',\n",
    "                         'CSIRO-ARCCSS.ACCESS-CM2',\n",
    "                        'EC-Earth-Consortium.EC-Earth3-Veg',\n",
    "                        'INM.INM-CM4-8',\n",
    "                          'INM.INM-CM5-0',\n",
    "                                  'MIROC.MIROC-ES2L',\n",
    "                                  'MRI.MRI-ESM2-0',\n",
    "                    'NIMS-KMA.KACE-1-0-G',\n",
    "                    'UA.MCM-UA-1-0',\n",
    "                     'NOAA-GFDL.GFDL-CM4',\n",
    "                    'NCAR.CESM2',\n",
    "                    'CSIRO.ACCESS-ESM1-5',\n",
    "                                 'MPI-M.MPI-ESM1-2-LR',\n",
    "                     'MIROC.MIROC6',\n",
    "                     'FIO-QLNM.FIO-ESM-2-0',\n",
    "                     'CCCma.CanESM5-CanOE',\n",
    "                    'CNRM-CERFACS.CNRM-ESM2-1',\n",
    "                    'CNRM-CERFACS.CNRM-CM6-1',\n",
    "                    'MOHC.UKESM1-0-LL',\n",
    "                    'NCAR.CESM2-WACCM',\n",
    "                    'IPSL.IPSL-CM6A-LR']:\n",
    "            print('Awesome news: {} was already completed!')\n",
    "            continue\n",
    "        historical_setup = 'CMIP.{}.historical.Lmon.gn'.format(gcm_label)\n",
    "\n",
    "        # first make the raster-to-polygon mapping for this grid\n",
    "        sample_file = ds_dict[historical_setup].isel(time=0).compute()\n",
    "        raster_basins, basin_poly_mask = rasterize_shapefile(basins, \n",
    "                                                                   sample_file, \n",
    "                                                                   'NAME')\n",
    "\n",
    "        print(\"Woohoo! You've finished rasterizing your shapefile for {}\".format(gcm_label))\n",
    "        if recalculate_historical:\n",
    "            basins_historical = map_gridded_to_basins(ds_dict[historical_setup].mrro, \n",
    "                                               raster_basins, basins)\n",
    "            basins_historical.to_file('{}_polygon_historical_fullbasins.shp'.format(gcm_label))\n",
    "            print(\"Excellent! You've finished the historical shapefile for {}\".format(gcm_label))\n",
    "\n",
    "        # rasterize the subbasin differently for every \n",
    "        if recalculate_future:\n",
    "            basins_future, basins_changes = {}, {}\n",
    "            for setup in ['ssp585']: # eventually do it for all setups\n",
    "                print(setup, gcm)\n",
    "                future_setup = 'ScenarioMIP.{}.{}.Lmon.gn'.format(gcm_label, setup)\n",
    "                basins_future[setup] = map_gridded_to_basins(ds_dict[future_setup].mrro, \n",
    "                                               raster_basins, basins)\n",
    "\n",
    "\n",
    "                basins_future[setup].to_file('{}_{}_polygon_future_fullbasins.shp'.format(gcm_label, setup))\n",
    "\n",
    "                basins_changes[setup] = basins.copy(deep=True)\n",
    "                for metric in ['mean', 'h_range']:\n",
    "                    basins_changes[setup][metric] = (basins_future[setup][metric] - \n",
    "                                                        basins_historical[metric])/basins_historical[metric]\n",
    "                basins_changes[setup].to_file('{}_{}_polygon_changes_fullbasins.shp'.format(gcm_label, setup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in ERA data to understand biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload = False\n",
    "# do the regridding_step without a kurbernetes cluster! or else will break!\n",
    "regridding_step = False\n",
    "variable = 'ro'\n",
    "if reload:\n",
    "    ds_era = xr.open_zarr(fsspec.get_mapper('gcs://pangeo-era5/reanalysis/spatial-analysis'),\n",
    "                  consolidated=True,\n",
    "                  chunks='auto')\n",
    "\n",
    "    ds_era = ds_era.rename({'latitude': 'lat', \n",
    "                            'longitude': 'lon'}).sel(time=slice('1985','2014'))[variable]\n",
    "    print('here!')\n",
    "    era_monthly = ds_era.resample(time='M').mean().load()\n",
    "    era_monthly.to_netcdf('era5_monthly_{}.nc'.format(variable))\n",
    "if regridding_step:\n",
    "    era_monthly_runoff = xr.open_dataset('era5_monthly_{}.nc'.format(variable))\n",
    "    common_grid_ds = xr.Dataset({'lat': (['lat'], \n",
    "                                         ds_dict['CMIP.NCAR.CESM2.historical.Lmon.gn'].lat.values),\n",
    "                     'lon': (['lon'], \n",
    "                             ds_dict['CMIP.NCAR.CESM2.historical.Lmon.gn'].lon.values)},)\n",
    "    regridder = xe.Regridder(era_monthly_runoff, common_grid_ds, 'bilinear', reuse_weights=True)\n",
    "    era_monthly_runoff_regridded = regridder(era_monthly_runoff)\n",
    "    era_monthly_runoff_regridded.to_netcdf('era5_monthly_{}_cesm2grid.nc'.format(variable))\n",
    "else:\n",
    "    era_monthly_runoff = xr.open_dataset('era5_monthly_runoff_cesm2grid.nc')    \n",
    "    era_min = era_monthly_runoff.groupby('time.year').min()\n",
    "    era_max = era_monthly_runoff.groupby('time.year').max()\n",
    "    era_range = era_max - era_min\n",
    "    era_range_mean = era_range.mean(dim='year')\n",
    "    era_range.to_netcdf('era_range.nc')\n",
    "    era_range_mean.to_netcdf('era_range_mean.nc')        \n",
    "    era_range_std = era_range.std(dim='year')          \n",
    "    era_range_std.to_netcdf('era_range_std.nc')\n",
    "    era_monthly_precip = xr.open_dataset('era5_monthly_tp_cesm2grid.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate average temp/precip for basin analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuse existing file: bilinear_721x1440_192x288.nc\n",
      "using dimensions ('lat', 'lon') from data variable t2m as the horizontal dimensions for this dataset.\n"
     ]
    }
   ],
   "source": [
    "reload = False\n",
    "# do the regridding_step without a kurbernetes cluster! or else will break!\n",
    "regridding_step = True\n",
    "variable = 't2m'\n",
    "if reload:\n",
    "    ds_era = xr.open_zarr(fsspec.get_mapper('gcs://pangeo-era5/reanalysis/spatial-analysis'),\n",
    "                  consolidated=True,\n",
    "                  chunks='auto')\n",
    "\n",
    "    ds_era = ds_era.rename({'latitude': 'lat', \n",
    "                            'longitude': 'lon'}).sel(time=slice('1985','2014'))[variable]\n",
    "    print('here!')\n",
    "    era_monthly = ds_era.mean(dim='time').load()\n",
    "    era_monthly.to_netcdf('era5_mean_{}.nc'.format(variable))\n",
    "if regridding_step:\n",
    "    era_monthly_runoff = xr.open_dataset('era5_mean_{}.nc'.format(variable))\n",
    "    common_grid_ds = xr.Dataset({'lat': (['lat'], \n",
    "                                         ds_dict['CMIP.NCAR.CESM2.historical.Lmon.gn'].lat.values),\n",
    "                     'lon': (['lon'], \n",
    "                             ds_dict['CMIP.NCAR.CESM2.historical.Lmon.gn'].lon.values)},)\n",
    "    regridder = xe.Regridder(era_monthly_runoff, common_grid_ds, 'bilinear', reuse_weights=True)\n",
    "    era_monthly_runoff_regridded = regridder(era_monthly_runoff)\n",
    "    era_monthly_runoff_regridded.to_netcdf('era5_mean_{}_cesm2grid.nc'.format(variable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate performance of GCMs over historical for runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload=True\n",
    "setups_metric_dict, setups_monthly_dict, setups_range_dict = {}, {}, {}\n",
    "if reload:\n",
    "# specify the common grid based upon one of the higher resolution grids\n",
    "    for setup in ['ssp585', 'historical']:\n",
    "        common_grid_ds = xr.Dataset({'lat': (['lat'], ds_dict['CMIP.NCAR.CESM2.historical.{}.gn'.format(\n",
    "                                                                                                analysis_timestep)].lat.values),\n",
    "                             'lon': (['lon'], ds_dict['CMIP.NCAR.CESM2.historical.{}.gn'.format( \n",
    "                                                                                        analysis_timestep)].lon.values)},)\n",
    "\n",
    "        regridded_dict = {'mean': {},\n",
    "                         'stdev': {},\n",
    "                         'range': {},\n",
    "                         'lowest_10thpercentile': {},\n",
    "                         'cv': {}}\n",
    "        regridded_monthly = {}\n",
    "        regrid=True\n",
    "#         for source_id in ['CNRM-ESM2-1', 'INM-CM4-8']:\n",
    "        for source_id in set(cat.df[cat.df['experiment_id']=='ssp585']['source_id']):\n",
    "        #for source_id in set(cat.df['source_id']):\n",
    "            institution_id = list(set(cat.df['institution_id'][cat.df['source_id']==source_id].values))[0]\n",
    "            # remove the scenarios that don't have historical\n",
    "            if analysis_timestep == 'Lmon':\n",
    "                if source_id in ['GFDL-ESM4', 'KACE-1-0-G', 'IPSL-CM6A-LR',\n",
    "                                'E3SM-1-1', 'CanESM5',\n",
    "                                'HadGEM3-GC31-LL', 'FGOALS-f3-L',\n",
    "                                'EC-Earth3','CESM2-WACCM-FV2',\n",
    "                                'SAM0-UNICON','E3SM-1-0','GISS-E2-1-H',\n",
    "                                'MPI-ESM1-2-HR']: # these ones don't work for ssp585\n",
    "                    continue\n",
    "            elif analysis_timestep == 'day':\n",
    "                if institution_id in ['EC-Earth-Consortium', 'CNRM-CERFACS'] or \\\n",
    "                    source_id in ['GFDL-ESM4', 'HadGEM3-GC31-LL', 'BCC-ESM1',\n",
    "                                  'MIROC-ES2L', 'SAM0-UNICON', 'MPI-ESM1-2-HR']:\n",
    "                    continue\n",
    "            if setup=='historical':\n",
    "                experiment_id='CMIP'\n",
    "            else:\n",
    "                experiment_id='ScenarioMIP'\n",
    "            # select historical period for comparison\n",
    "            working_ds_historical = ds_dict['{}.{}.{}.{}.{}.gn'.format(experiment_id, institution_id, \n",
    "                                            source_id, setup, \n",
    "                                            analysis_timestep)][variable_of_interest].sel(\n",
    "                                            time=slices[setup]).chunk(\n",
    "                                        chunks={'lat': -1, 'lon': -1, 'time': 1000})\n",
    "            if len(working_ds_historical.time) != 360:\n",
    "                continue\n",
    "            # make the regridder for these files\n",
    "            # TODO: fix the 'lon_b' inputs to allow use of conservative remapping\n",
    "            print(source_id)\n",
    "            regridder = xe.Regridder(working_ds_historical, common_grid_ds,\n",
    "                                     'bilinear', reuse_weights=True)     \n",
    "            regridded_historical = regridder(working_ds_historical)\n",
    "            regridded_monthly[source_id] = regridded_historical.assign_coords(time=slices_ranges[setup])\n",
    "            regridded_dict['mean'][source_id] = annual_mean(regridded_historical)\n",
    "            regridded_dict['stdev'][source_id] = stdev(regridded_historical, analysis_timestep, freq='monthly')\n",
    "            regridded_dict['lowest_10thpercentile'][source_id] = lowest_10thpercentile(regridded_historical, analysis_timestep)\n",
    "            regridded_dict['range'][source_id] = monthly_intraannual_range(regridded_historical, analysis_timestep)\n",
    "            regridded_dict['cv'][source_id] = stdev(regridded_historical, analysis_timestep, freq='monthly')/annual_mean(regridded_historical)\n",
    "\n",
    "        metric_dict = {}\n",
    "        for metric in ['mean', 'stdev', 'lowest_10thpercentile', 'cv']:\n",
    "            metric_dict[metric] = xr.concat([regridded_dict[metric][key] for key in regridded_dict[metric].keys()], \n",
    "                              pd.Index(regridded_dict[metric].keys(), name='gcm')).chunk(chunks=15)\n",
    "\n",
    "#         combine all data arrays in the dictionary into a single dataset\n",
    "        setups_metric_dict[setup] = xr.concat([metric_dict[metric] for metric in metric_dict.keys()], \n",
    "                                  pd.Index(metric_dict.keys(), name='metric'))\n",
    "        setups_monthly_dict[setup] = xr.concat([regridded_monthly[gcm] for gcm in regridded_monthly.keys()], \n",
    "                                  pd.Index(regridded_monthly.keys(), name='gcm'))\n",
    "        setups_range_dict[setup] = xr.concat([regridded_dict['range'][key] for key in regridded_dict['range'].keys()],\n",
    "                            pd.Index(regridded_dict['range'].keys(), name='gcm')).chunk(chunks=15)\n",
    "    setups_metric_ds = xr.concat([setups_metric_dict[setup] \n",
    "                                  for setup in setups_metric_dict.keys()],\n",
    "                                 pd.Index(setups_metric_dict.keys(), name='experiment'))\n",
    "    setups_monthly_ds = xr.concat([setups_monthly_dict[setup] \n",
    "                                  for setup in setups_monthly_dict.keys()],\n",
    "                                 pd.Index(setups_monthly_dict.keys(), name='experiment'))\n",
    "    setups_range_ds = xr.concat([setups_range_dict[setup] \n",
    "                                  for setup in setups_range_dict.keys()],\n",
    "                                 pd.Index(setups_range_dict.keys(), name='experiment'))\n",
    "        #     historical_ds_monthly.to_netcdf('cmip6_historical_34gcms_runoff_monthly.nc')\n",
    "    #     range_ds.to_netcdf('cmip6_historical_34gcms_runoff_range_monthly.nc')\n",
    "#     historical_ds.to_netcdf('cmip6_historical_34gcms_runoff_metrics.nc')\n",
    "\n",
    "else:\n",
    "    historical_ds_monthly = xr.open_dataset('cmip6_historical_34gcms_runoff_monthly.nc').mrro\n",
    "    range_ds = xr.open_dataset('cmip6_historical_34gcms_runoff_range_monthly.nc')\n",
    "    historical_ds = xr.open_dataset('cmip6_historical_34gcms_runoff_metrics.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setups_monthly_ds.to_netcdf('cmip6_historical_ssp585_monthly.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a mask to only show land pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_mask = ~np.isnan(historical_ds.sel(gcm='CESM2', metric='mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare ERA to GCM simulations  - one plot each for each GCM\n",
    "### Goal: show how well the gcms capture state/variability of runoff\n",
    "* mean  - measure of overall water balance\n",
    "* stdev of monthly - how well does system capture variability\n",
    "* range - how well does the system capture intraannual variability\n",
    "* lowest 10th percentile of low monthly runoff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical ERA5 runoff (Gridded) and CMIP6 biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(ncols=2, figsize=(14,4),\n",
    "                          subplot_kw=dict(projection=ccrs.Robinson()))\n",
    "\n",
    "era_annual_mean = (era_monthly_runoff.mean(dim='time').rename({'ro':'mrro'})*24*365).mrro # might have to add \".mrro\"\n",
    "\n",
    "# plot the ERA5\n",
    "plot_nicely(axarr[0], era_annual_mean.where(~np.isnan(historical_ds.sel(metric='mean', gcm='CESM2')).mrro), # might have to add mrro\n",
    "            vmin=0, vmax=1, cmap='viridis_r',\n",
    "           cbar_label='Runoff [m/year]', title='Annual runoff ERA5 (1985-2014)')\n",
    "\n",
    "# plot the historical CMIP6 biases w.r.t. ERA5\n",
    "mme = (historical_ds.sel(metric='mean'\n",
    "                           ).where(land_mask)*86400*365/1000).mean(dim='gcm').mrro # might have to add mrro\n",
    "bias_to_plot = bias(mme, era_annual_mean, 'percent')\n",
    "plot_nicely(axarr[1], bias_to_plot, \n",
    "            vmin=-100, vmax=100, cmap='RdBu',\n",
    "           cbar_label='Bias [%]', title='Comparing annual runoff (1985-2014) from '\n",
    "            'CMIP6\\nmultimodel ensemble (n={ngcms}) mean and ERA5'.format(ngcms=len(historical_ds.gcm)))\n",
    "plt.tight_layout()\n",
    "fig.savefig('../figures/era5_runoff_and_CMIP6_bias.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical ERA5 variability in monthly runoff (gridded) and CMIP6 biases in that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(ncols=2, figsize=(14,4),\n",
    "                          subplot_kw=dict(projection=ccrs.Robinson()))\n",
    "# need to fix this 30 day issue (make it actually monthly runoff)\n",
    "era_annual_stdev = (era_monthly_runoff*30*24).std(dim='time').rename({'ro':'mrro'}).mrro\n",
    "\n",
    "# plot the ERA5\n",
    "plot_nicely(axarr[0], era_annual_stdev.where(~np.isnan(historical_ds.sel(metric='stdev', gcm='CESM2'))), \n",
    "            vmin=0, vmax=0.1, cmap='viridis_r',\n",
    "           cbar_label='Std. Dev in monthly runoff [m/month]', title='Variability in monthly runoff ERA5 (1985-2014)')\n",
    "\n",
    "# plot the historical CMIP6 biases w.r.t. ERA5\n",
    "mmstdev = (historical_ds.sel(metric='stdev',\n",
    "                           ).where(land_mask)*86400*30/1000).mean(dim='gcm')\n",
    "bias_to_plot = bias(mmstdev, era_annual_stdev, 'percent')\n",
    "plot_nicely(axarr[1], bias_to_plot, \n",
    "            vmin=-200, vmax=200, cmap='RdBu',\n",
    "           cbar_label='Bias [%]', title='Comparing monthly runoff variability (1985-2014)'\n",
    "            ' from CMIP6\\nmultimodel ensemble (n={ngcms}) mean and ERA5'.format(ngcms=len(historical_ds.gcm)))\n",
    "plt.tight_layout()\n",
    "fig.savefig('../figures/era5_runoff_and_CMIP6_stdev_bias.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical hydrologic range ERA5 and CMIP6 comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrologic_range = (range_ds.mean(dim=['year', 'gcm'])*30)/ \\\n",
    "                    (historical_ds.sel(metric='mean').mean(dim='gcm')*365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(ncols=2, figsize=(12,5))\n",
    "two_setups = {'Northern Russia': (62, 100), \n",
    "              'Amazon': (-2,285)}\n",
    "for i, (setup, (lat, lon))  in enumerate(two_setups.items()):\n",
    "    historical_ds_monthly.sel(lat=lat, lon=lon, \n",
    "                              method='nearest').isel(time=slice(150,200)).plot.line(ax=axarr[i],\n",
    "                                                                                    x='time', \n",
    "                                                                                    alpha=0.1,\n",
    "                                                                                    color='k',\n",
    "                                                                                   add_legend=False)\n",
    "    axarr[i].text(0.1, 0.9, 'Hydrologic range: '+str(np.round(hydrologic_range.sel(lat=lat, \n",
    "                                       lon=lon, \n",
    "                                       method='nearest').values, 2)),\n",
    "                  transform=axarr[i].transAxes)\n",
    "    axarr[i].set_title(setup)\n",
    "plt.tight_layout()\n",
    "plt.savefig('intraannual_range_cartoon.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(ncols=2, figsize=(14,4),\n",
    "                          subplot_kw=dict(projection=ccrs.Robinson()))\n",
    "\n",
    "era_hydrologic_range = ((era_range_mean*30)/(era_monthly_runoff.mean(dim='time')*365)).ro.where(\n",
    "                        ~np.isnan(historical_ds.sel(metric='stdev', gcm='CESM2')))\n",
    "\n",
    "# plot the ERA5\n",
    "plot_nicely(axarr[0], era_hydrologic_range, \n",
    "            vmin=0, vmax=1, cmap='viridis_r',\n",
    "           cbar_label='Hydrologic range ratio [-]', title='Intraannual hydrologic range of '\n",
    "                                                        'monthly runoff ERA5 (1985-2014)')\n",
    "\n",
    "# plot the historical CMIP6 biases w.r.t. ERA5\n",
    "bias_to_plot = bias(hydrologic_range, era_hydrologic_range, 'absolute')\n",
    "plot_nicely(axarr[1], bias_to_plot, \n",
    "            vmin=-0.5, vmax=0.5, cmap='RdBu',\n",
    "           cbar_label='Bias [-]', title='Comparing intraannual hydrologic range (1985-2014)'\n",
    "            '\\nfrom CMIP6 multimodel ensemble (n={ngcms}) mean and ERA5'.format(ngcms=len(historical_ds.gcm)))\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('../figures/era5_runoff_and_CMIP6_hydrologic_range_bias.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical ERA5 CV in monthly runoff (gridded) and CMIP6 biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(ncols=2, figsize=(14,4),\n",
    "                          subplot_kw=dict(projection=ccrs.Robinson()))\n",
    "# need to fix this 30 day issue (make it actually monthly runoff)\n",
    "era_annual_stdev = (era_monthly_runoff*30*24).std(dim='time').rename({'ro':'mrro'}).mrro\n",
    "era_annual_cv = era_annual_stdev/(era_monthly_runoff.mean(dim='time').rename({'ro':'mrro'}).mrro*30*24)\n",
    "\n",
    "# plot the ERA5\n",
    "plot_nicely(axarr[0], era_annual_cv.where(~np.isnan(historical_ds.sel(metric='mean', gcm='CESM2').mrro)), \n",
    "            vmin=0, vmax=5, cmap='viridis_r',\n",
    "           cbar_label='C.V. in monthly runoff [m/month]', title='Variability in monthly runoff ERA5 (1985-2014)')\n",
    "\n",
    "# plot the historical CMIP6 biases w.r.t. ERA5\n",
    "mmstdev = (historical_ds.mrro.sel(metric='stdev',\n",
    "                           ).where(land_mask)*86400*30/1000).mean(dim='gcm')\n",
    "mmcv = mmstdev/(mme/365*30)\n",
    "\n",
    "bias_to_plot = bias(mmcv, era_annual_cv, 'percent').mrro\n",
    "plot_nicely(axarr[1], bias_to_plot, \n",
    "            vmin=-200, vmax=200, cmap='RdBu',\n",
    "           cbar_label='Bias [%]', title='Comparing monthly runoff variability (1985-2014)'\n",
    "            ' from CMIP6\\nmultimodel ensemble (n={}) mean and ERA5'.format(len(historical_ds.gcm)))\n",
    "plt.tight_layout()\n",
    "fig.savefig('../figures/era5_runoff_and_CMIP6_cv_bias.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now plotting basin averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First bias in mean basin runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(ncols=2, figsize=(14,4), \n",
    "                          subplot_kw=dict(projection=ccrs.Robinson()))\n",
    "\n",
    "era_hydrologic_range = ((era_range_mean*30)/(era_monthly_runoff.mean(dim='time')*365)).ro.where(\n",
    "                        ~np.isnan(historical_ds.sel(metric='stdev', gcm='CESM2')))\n",
    "\n",
    "\n",
    "era_annual_mean = (era_monthly_runoff.mean(dim='time').rename({'ro':'mrro'})*24*365).mrro\n",
    "basins = map_gridded_to_basins(era_annual_mean, mask, basins)\n",
    "p = basins.plot(ax = axarr[0], column='value_to_plot', vmax=1.5, \n",
    "            zorder=40, transform=ccrs.PlateCarree(), legend=True,\n",
    "                cmap='viridis_r',\n",
    "               legend_kwds={\"label\": \"Runoff [m/year]\",\n",
    "                           \"extend\": \"max\"})\n",
    "add_cartopy_elements(axarr[0])\n",
    "p.set_title('Annual areally-averaged runoff ERA5 (1985-2014)')\n",
    "\n",
    "\n",
    "# plot the historical CMIP6 biases w.r.t. ERA5\n",
    "basins = map_gridded_to_basins(era_annual_mean, mask, basins, comparison_da=mme)\n",
    "p = basins.plot(ax = axarr[1], column='value_to_plot', vmax=100,\n",
    "                vmin=-100, cmap='RdBu',\n",
    "            zorder=40, transform=ccrs.PlateCarree(), legend=True,\n",
    "               legend_kwds={\"label\": \"Annual bias in area-averaged runoff [%]\",\n",
    "                           'extend': 'max'})\n",
    "p.set_title('Bias in CMIP6 multimodel (n={}) mean\\nareally-averaged'.format(len(historical_ds.gcm))+\\\n",
    "            ' runoff (CMIP6 - ERA5; 1985-2014)')\n",
    "\n",
    "add_cartopy_elements(axarr[1])\n",
    "plt.tight_layout()\n",
    "fig.savefig('../figures/era5_runoff_and_CMIP6_basins_bias.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second, bias in mean basin hydrologic range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(ncols=2, figsize=(14,4), \n",
    "                          subplot_kw=dict(projection=ccrs.Robinson()))\n",
    "\n",
    "basins = map_gridded_to_basins((era_monthly_runoff.rename({'ro':'mrro'})*24*30).mrro, \n",
    "                                mask, basins, metric='hydrologic_range')\n",
    "p = basins[basins['Sufficiently big']==True].plot(ax = axarr[0], \n",
    "                        column='value_to_plot', vmax=0.4, vmin=0,\n",
    "            zorder=40, transform=ccrs.PlateCarree(), legend=True,\n",
    "                cmap='viridis_r',\n",
    "               legend_kwds={\"label\": \"Hydrologic range [-]\",\n",
    "                           \"extend\": \"neither\"})\n",
    "add_cartopy_elements(axarr[0])\n",
    "p.set_title('Hydrologic range of global basins according to ERA5 (1985-2014)')\n",
    "\n",
    "\n",
    "# plot the historical CMIP6 biases w.r.t. ERA5\n",
    "\n",
    "\n",
    "basins = map_gridded_to_basins((era_monthly_runoff.rename({'ro':'mrro'})*24*30).mrro, \n",
    "                               mask, basins, \n",
    "                               comparison_da=historical_ds_monthly, \n",
    "                               metric='hydrologic_range')\n",
    "p = basins[basins['Sufficiently big']==True].plot(ax = axarr[1], column='value_to_plot', vmax=0.3,\n",
    "                vmin=-0.3, cmap='RdBu',\n",
    "            zorder=40, transform=ccrs.PlateCarree(), legend=True,\n",
    "               legend_kwds={\"label\": \"Bias in hydrologic range [-]\",\n",
    "                           'extend': 'max'})\n",
    "p.set_title('Bias in CMIP6 multimodel (n={}) mean\\nhydrologic range of'.format(len(historical_ds_monthly.gcm))+\\\n",
    "            ' runoff (CMIP6 - ERA5; 1985-2014)')\n",
    "\n",
    "add_cartopy_elements(axarr[1])\n",
    "plt.tight_layout()\n",
    "fig.savefig('../figures/era5_runoff_and_CMIP6_basins_hydrologic_range_bias.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot change under ssp585"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, change in the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(ncols=2, figsize=(14,4),\n",
    "                          subplot_kw=dict(projection=ccrs.Robinson()))\n",
    "\n",
    "historical_mean = setups_metric_ds.sel(metric='mean', \n",
    "                        experiment='historical').mean(dim='gcm')*86400*365/1000 # might have to add \".mrro\"\n",
    "\n",
    "# plot the ERA5\n",
    "plot_nicely(axarr[0], historical_mean.where(~np.isnan(setups_metric_ds.sel(metric='mean',\n",
    "                                                                           gcm='CESM2').isel(experiment=1))), # might have to add mrro\n",
    "            vmin=0, vmax=1, cmap='viridis_r',\n",
    "           cbar_label='Runoff [m/year]', title='Historical runoff CMIP6 (1985-2014)')\n",
    "\n",
    "# plot the historical CMIP6 biases w.r.t. ERA5\n",
    "future_mean = setups_metric_ds.sel(metric='mean',\n",
    "    experiment='ssp585').mean(dim='gcm')*86400*365/1000 # might have to add \".mrro\"\n",
    "\n",
    "change_plot = bias(future_mean, historical_mean, 'percent')\n",
    "plot_nicely(axarr[1], change_plot.where(~np.isnan(setups_metric_ds.sel(metric='mean',\n",
    "                                                    gcm='CESM2').isel(experiment=1))), \n",
    "            vmin=-100, vmax=100, cmap='RdBu',\n",
    "           cbar_label='Change in annual runoff [%]', title='Change in future (SSP585) runoff (2070-2099) from '\n",
    "            'CMIP6\\nmultimodel ensemble (n={ngcms}) w.r.t. 2000s'.format(ngcms=20))\n",
    "plt.tight_layout()\n",
    "fig.savefig('../figures/cmip6_ssp585_changes.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basin average changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# future_mean = future_mean.rename({'lon': 'longitude',\n",
    "#                    'lat': 'latitude'})\n",
    "# future_mean = future_mean.assign_coords(longitude=(((future_mean.longitude + 180) % 360) \n",
    "#                                      - 180)).sortby('longitude')\n",
    "\n",
    "lat = mask.latitude.values\n",
    "lon = mask.longitude.values\n",
    "ID_REGION=2\n",
    "sel_mask = mask.where(mask == ID_REGION).values\n",
    "if (~np.isnan(sel_mask)).sum() < 10:\n",
    "    basins_gdf.at[ID_REGION, 'Sufficiently big'] = False\n",
    "print('okay')\n",
    "id_lon = lon[np.where(~np.all(np.isnan(sel_mask), axis=0))]\n",
    "id_lat = lat[np.where(~np.all(np.isnan(sel_mask), axis=1))]\n",
    "out_sel = future_mean.sel(latitude = slice(id_lat[0], id_lat[-1]), \n",
    "                longitude = slice(id_lon[0], id_lon[-1])\n",
    "               ).where(mask == ID_REGION)\n",
    "float(out_sel.mean(dim = ['latitude', 'longitude']).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(ncols=2, figsize=(14,4), \n",
    "                          subplot_kw=dict(projection=ccrs.Robinson()))\n",
    "historical_mean = setups_metric_ds.sel(metric='mean', \n",
    "                                       experiment='historical').mean(dim='gcm')\n",
    "# historical_mean = (setups_monthly_ds.sel(\n",
    "#     experiment='historical').mean(dim=['time', 'gcm']))*86400*365/1000\n",
    "basins = map_gridded_to_basins(historical_mean, mask, basins)\n",
    "p = basins.plot(ax = axarr[0], column='value_to_plot', vmax=1.5, \n",
    "            zorder=40, transform=ccrs.PlateCarree(), legend=True,\n",
    "                cmap='viridis_r',\n",
    "               legend_kwds={\"label\": \"Runoff [m/year]\",\n",
    "                           \"extend\": \"max\"})\n",
    "add_cartopy_elements(axarr[0])\n",
    "p.set_title('Annual areally-averaged runoff historical (1985-2014)')\n",
    "\n",
    "future_mean = setups_metric_ds.sel(metric='mean', \n",
    "                                       experiment='ssp585').mean(dim='gcm')\n",
    "\n",
    "# plot the historical CMIP6 biases w.r.t. ERA5\n",
    "basins = map_gridded_to_basins(historical_mean, mask, basins, comparison_da=future_mean)\n",
    "p = basins.plot(ax = axarr[1], column='value_to_plot', vmax=100,\n",
    "                vmin=-100, cmap='RdBu',\n",
    "            zorder=40, transform=ccrs.PlateCarree(), legend=True,\n",
    "               legend_kwds={\"label\": \"Annual change in area-averaged runoff [%]\",\n",
    "                           'extend': 'max'})\n",
    "p.set_title('Change in future (SSP585) runoff (2070-2099) from '\n",
    "            'CMIP6\\nmultimodel ensemble (n={ngcms}) w.r.t. 2000s'.format(ngcms=20))\n",
    "\n",
    "add_cartopy_elements(axarr[1])\n",
    "plt.tight_layout()\n",
    "fig.savefig('../figures/cmip6_ssp585_changes_basins.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all basins on scatter to show ensemble disagreement\n",
    "### columbia = 36\n",
    "### amazon = 175\n",
    "### yenisey = 2\n",
    "### nile = 107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridded_basin_behavior(da, masks, basins_gdf_in, dataset):\n",
    "    '''Input: gridded xarray data array of cmip6 on lat/lon coordinates\n",
    "    with multiple ensemble members (monthly timestep)\n",
    "    dataset is a string of either \"era5\" or \"cmip6\"\n",
    "    '''\n",
    "    da = da.rename({'lon': 'longitude',\n",
    "                       'lat': 'latitude'})\n",
    "    da = da.assign_coords(longitude=(((da.longitude + 180) % 360) \n",
    "                                         - 180)).sortby('longitude')\n",
    "    \n",
    "#     initialize the geopandas df with the metrics you'll calculate\n",
    "    if dataset=='cmip6':\n",
    "        metrics = ['mean', 'std', 'hydrologic_range',\n",
    "                   'upper_quartile_mean', 'lower_quartile_mean',\n",
    "                  'upper_quartile_std', 'lower_quartile_std',\n",
    "                  'upper_quartile_hydrologic_range', 'lower_quartile_hydrologic_range']\n",
    "    elif dataset=='era5':\n",
    "        metrics = ['mean', 'std']\n",
    "    basins_gdf_out = basins_gdf_in.copy(deep=True)\n",
    "    basins_gdf_out['Sufficiently big'] = 0\n",
    "    for metric in metrics:\n",
    "        basins_gdf_out[metric] = np.nan\n",
    "    lat = masks.latitude.values\n",
    "    lon = masks.longitude.values\n",
    "    for ID_REGION in range(0,254):\n",
    "        print(ID_REGION)\n",
    "        sel_mask = masks.where(masks == ID_REGION).values\n",
    "        if (~np.isnan(sel_mask)).sum() < 10:\n",
    "            print('{} is too small!'.format(ID_REGION))\n",
    "            basins_gdf_out.at[ID_REGION, 'Sufficiently big'] = 0\n",
    "            continue\n",
    "        else:\n",
    "            basins_gdf_out.at[ID_REGION, 'Sufficiently big'] = (~np.isnan(sel_mask)).sum()\n",
    "        id_lon = lon[np.where(~np.all(np.isnan(sel_mask), axis=0))]\n",
    "        id_lat = lat[np.where(~np.all(np.isnan(sel_mask), axis=1))]\n",
    "        out_sel = da.sel(latitude = slice(id_lat[0], id_lat[-1]), \n",
    "                        longitude = slice(id_lon[0], id_lon[-1])\n",
    "                       ).compute().where(masks == ID_REGION)\n",
    "        monthly_mean_basin = out_sel.mean(dim=['latitude', 'longitude'])\n",
    "        for metric in ['mean', 'std', 'hydrologic_range']:\n",
    "            if metric == 'mean':\n",
    "                try:\n",
    "                    ensemble = monthly_mean_basin.mean(dim=['time']).mrro.values\n",
    "                except:\n",
    "                    ensemble = monthly_mean_basin.mean(dim=['time'])\n",
    "            elif metric == 'std':\n",
    "                try:\n",
    "                    ensemble = monthly_mean_basin.std(dim=['time']).mrro.values\n",
    "                except:\n",
    "                    ensemble = monthly_mean_basin.std(dim=['time'])\n",
    "            elif metric =='hydrologic_range':\n",
    "                if dataset=='cmip6':\n",
    "                    ensemble = basin_average_intraannual_range(out_sel, \n",
    "                                                          multiple_ensemble_members=True,\n",
    "                                                          return_ensemble=True)\n",
    "                elif dataset == 'era5':\n",
    "                    ensemble = basin_average_intraannual_range(out_sel, \n",
    "                                                          multiple_ensemble_members=False,\n",
    "                                                          return_ensemble=False)\n",
    "            if dataset=='cmip6':  \n",
    "                basins_gdf_out.at[ID_REGION, metric] = float(ensemble.mean(dim='gcm').values)\n",
    "                basins_gdf_out.at[ID_REGION, 'upper_quartile_'+metric] = np.quantile(ensemble.values, 0.75)\n",
    "                basins_gdf_out.at[ID_REGION, 'lower_quartile_'+metric] = np.quantile(ensemble.values, 0.25)\n",
    "            elif dataset=='era5':\n",
    "                basins_gdf_out.at[ID_REGION, metric] = ensemble\n",
    "    return basins_gdf_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_basins.to_file(\"basins_with_quartiles_partial.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_ds_monthly = gridded_basin_behavior(historical_ds_monthly*86400*30/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_basins = gridded_basin_behavior(historical_ds_monthly*86400*30/1000, \n",
    "                                    mask, basins, dataset='cmip6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_basins.to_file(\"basins_with_hydrologic_ranges_quartiles.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_basins = gridded_basin_behavior(era_monthly_runoff.rename({'ro':'mrro'})*24*30, \n",
    "                                    mask, basins, dataset='era5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_basins.to_file('basins_era_range.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(ncols=2, figsize=(14,4), \n",
    "                          subplot_kw=dict(projection=ccrs.Robinson()))\n",
    "\n",
    "era_annual_mean = (era_monthly_runoff.mean(dim='time').rename({'ro':'mrro'})*24*365).mrro\n",
    "basins = map_gridded_to_basins(era_annual_mean, mask, basins)\n",
    "p = basins.plot(ax = axarr[0], column='value_to_plot', vmax=1.5, \n",
    "            zorder=40, transform=ccrs.PlateCarree(), legend=True,\n",
    "                cmap='viridis_r',\n",
    "               legend_kwds={\"label\": 'Std. Dev in monthly runoff [m/month]',\n",
    "                           \"extend\": \"max\"})\n",
    "p.title('')\n",
    "add_cartopy_elements(axarr[0])\n",
    "\n",
    "\n",
    "# plot the historical CMIP6 biases w.r.t. ERA5\n",
    "basins = map_gridded_to_basins(era_annual_mean, mask, basins, comparison_da=mme)\n",
    "p = basins.plot(ax = axarr[1], column='value_to_plot', vmax=100,\n",
    "                vmin=-100, cmap='RdBu',\n",
    "            zorder=40, transform=ccrs.PlateCarree(), legend=True,\n",
    "               legend_kwds={\"label\": \"Annual bias in area-averaged runoff [%]\"})\n",
    "\n",
    "add_cartopy_elements(axarr[1])\n",
    "fig.savefig('../figures/era5_runoff_and_CMIP6_basins_bias.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'mean'\n",
    "plot_attributes = {'absolute': {'cbar_label': 'Bias [m/year]',\n",
    "                                'var_limits': [-1,1]},\n",
    "                  'percent': {'cbar_label': 'Bias [%]',\n",
    "                                'var_limits': [-100,100]},}\n",
    "for method in ['absolute', 'percent']:\n",
    "    cbar_label='Runoff [m/year]'\n",
    "    mme = (historical_ds.mrro.sel(metric=metric\n",
    "                           ).where(land_mask))\n",
    "    bias_to_plot = bias(mme*86400*365/1000, era_annual_mean, method)\n",
    "    p = bias_to_plot.ro.plot.contourf(col='gcm', col_wrap=3,\n",
    "                                   vmin=plot_attributes[method]['var_limits'][0],\n",
    "                                      vmax=plot_attributes[method]['var_limits'][1], \n",
    "                                    transform=ccrs.PlateCarree(),\n",
    "                                    subplot_kws={'projection': ccrs.Robinson()},# add_colorbar=False,\n",
    "                                    cmap='RdBu', levels=11, cbar_kwargs={'label': plot_attributes[method]['cbar_label']},\n",
    "                                    aspect=3, size=4)\n",
    "    p.fig.savefig('../figures/cmip6_historical_by_gcm_{}_bias_{}.png'.format(metric, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['mean', 'stdev', 'lowest_10thpercentile', 'cv']:\n",
    "    cbar_label='Runoff [m/year]'\n",
    "    p = (historical_ds.mrro.sel(metric=metric\n",
    "                               ).where(land_mask)*86400*365/1000).plot.contourf(col='gcm', col_wrap=3,\n",
    "                                   vmax=2,vmin=0, \n",
    "                                    transform=ccrs.PlateCarree(),\n",
    "                                    subplot_kws={'projection': ccrs.Robinson()},# add_colorbar=False,\n",
    "                                    cmap='viridis_r', levels=11, cbar_kwargs={'label': cbar_label},\n",
    "                                    aspect=3, size=4)\n",
    "    for ax in p.axes.flat:\n",
    "        ax.coastlines()\n",
    "        ax.gridlines()\n",
    "        ax.add_feature(cartopy.feature.BORDERS, linestyle='-')\n",
    "        ax.add_feature(cartopy.feature.OCEAN, color='lightgrey')\n",
    "    p.fig.savefig('../figures/cmip6_historical_{}.png'.format(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['mean', 'stdev', 'lowest_10thpercentile']:\n",
    "    cbar_label='Runoff [m/year]'\n",
    "    p = (historical_ds.mrro.sel(metric=metric\n",
    "                               ).where(land_mask)*86400*365/1000).plot.contourf(col='gcm', col_wrap=3,\n",
    "                                   vmax=2,vmin=0, \n",
    "                                    transform=ccrs.PlateCarree(),\n",
    "                                    subplot_kws={'projection': ccrs.Robinson()},# add_colorbar=False,\n",
    "                                    cmap='viridis_r', levels=11, cbar_kwargs={'label': cbar_label},\n",
    "                                    aspect=3, size=4)\n",
    "    for ax in p.axes.flat:\n",
    "        ax.coastlines()\n",
    "        ax.gridlines()\n",
    "        ax.add_feature(cartopy.feature.BORDERS, linestyle='-')\n",
    "        ax.add_feature(cartopy.feature.OCEAN, color='lightgrey')\n",
    "    p.fig.savefig('../figures/cmip6_historical_{}.png'.format(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(nrows=len(historical_ds.gcm), ncols=1, figsize=(14,40),\n",
    "                          subplot_kw=dict(projection=ccrs.Robinson()))\n",
    "obs = (era_monthly_runoff.mean(dim='time').rename({'ro':'mrro'})*24*365).mrro\n",
    "\n",
    "for i, gcm in enumerate(historical_ds.gcm.values):\n",
    "    sim = (historical_ds.mrro.sel(metric='mean', gcm=gcm).where(~np.isnan(land_mask))*86400*365/1000)\n",
    "    plot_nicely(axarr[i], (( sim - obs ) / obs) *100, \n",
    "            vmin=-100, vmax=100, cmap='RdBu',\n",
    "           cbar_label='Bias [%]', title='Bias of mean annual runoff from {}'.format(gcm))\n",
    "fig.savefig('../figures/gcms_annual_runoff_bias_wrt_ERA5.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_id in set(cat.df['source_id']):\n",
    "    institution_id = list(set(cat.df['institution_id'][cat.df['source_id']==source_id].values))[0]\n",
    "    # remove the scenarios that don't have historical\n",
    "    if institution_id in ['EC-Earth-Consortium', 'CNRM-CERFACS'] or \\\n",
    "        source_id in ['GFDL-ESM4', 'HadGEM3-GC31-LL', 'BCC-ESM1',\n",
    "                      'MIROC-ES2L', 'SAM0-UNICON', 'MPI-ESM1-2-HR']:\n",
    "        continue\n",
    "    working_ds_historical = ds_dict['CMIP.{}.{}.historical.day.gn'.format(institution_id, \n",
    "                                    source_id)][variable_of_interest].sel(time=historical_slice).chunk(\n",
    "                                chunks={'lat': 100, 'lon': -1, 'time': 1000})\n",
    "    if regrid:\n",
    "        regridder = xe.Regridder(working_ds_historical, common_grid_ds,\n",
    "                                 'bilinear', reuse_weights=True)     \n",
    "\n",
    "        calculate_change(function(regridder(working_ds_historical)), \n",
    "                                                  function(regridder(working_ds_future)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(nrows=3, ncols=3, figsize=(14,6),\n",
    "                          subplot_kw=dict(projection=ccrs.Robinson()))\n",
    "for (i, source_id) in enumerate(change_dict.keys()):\n",
    "    ax = axarr[i]\n",
    "    ax.set_global()\n",
    "    ax.coastlines()\n",
    "    q = change_ds.sel(gcm=gcm).plot(ax=ax, \n",
    "                                    transform=ccrs.PlateCarree(), \n",
    "                                    vmin=-100, vmax=100, \n",
    "                                    cmap='RdBu', add_colorbar=False) # plot a colormap in transformed coordinates\n",
    "\n",
    "    ax.add_feature(cartopy.feature.COASTLINE)\n",
    "    ax.add_feature(cartopy.feature.BORDERS, linestyle='-')\n",
    "    plt.title('Patterns of global annual runnof change',fontsize=16, ha='center');\n",
    "    # plt.savefig('../figures/future_runoff_changes.png',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-do list\n",
    "* seasonal cycle (daily average for an average year within historical and future periods)\n",
    "* function for each of these temporal metrics:\n",
    "1. change in centroid of timing\n",
    "1. change in lowest 30 day period magnitude\n",
    "1. total deviation from the mean\n",
    "1. duration of low flow\n",
    "* function for each of these spatiotemporal metrics:\n",
    "1. within a given basin what is the variability - to-do in this is figureing out shapefile masking for river basins"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
